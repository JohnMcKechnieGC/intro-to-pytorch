{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Classification\n",
    "Often referred to as the \"Hello, World!\" of deep learning.\n",
    "\n",
    "Challenge:\n",
    "- Create and train a neural network using PyTorch to classify handwritten digits from the MNIST dataset. The MNIST dataset consists of 28x28 pixel grayscale images of handwritten digits (0-9).\n",
    "- Experiment with different network architectures, learning rates, and batch sizes and compare the results in terms of accuracy.\n",
    "- Study the code with reference to the PyTorch documentation and any other useful learning resources. Add useful comments to the code that demonstrate your understanding of what each part does. Make any changes that you think are beneficial either from a machine learning or software engineering perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download the training data\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download the test data\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Flatten 28x28 to a 784 vector for fully connected layer\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # 10 output classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize the Model, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for classification with N classes\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.356\n",
      "Epoch: 1, Batch: 200, Loss: 0.444\n",
      "Epoch: 1, Batch: 300, Loss: 0.401\n",
      "Epoch: 1, Batch: 400, Loss: 0.356\n",
      "Epoch: 1, Batch: 500, Loss: 0.324\n",
      "Epoch: 1, Batch: 600, Loss: 0.289\n",
      "Epoch: 1, Batch: 700, Loss: 0.281\n",
      "Epoch: 1, Batch: 800, Loss: 0.263\n",
      "Epoch: 1, Batch: 900, Loss: 0.219\n",
      "Epoch: 2, Batch: 100, Loss: 0.198\n",
      "Epoch: 2, Batch: 200, Loss: 0.218\n",
      "Epoch: 2, Batch: 300, Loss: 0.185\n",
      "Epoch: 2, Batch: 400, Loss: 0.174\n",
      "Epoch: 2, Batch: 500, Loss: 0.168\n",
      "Epoch: 2, Batch: 600, Loss: 0.179\n",
      "Epoch: 2, Batch: 700, Loss: 0.165\n",
      "Epoch: 2, Batch: 800, Loss: 0.157\n",
      "Epoch: 2, Batch: 900, Loss: 0.161\n",
      "Epoch: 3, Batch: 100, Loss: 0.135\n",
      "Epoch: 3, Batch: 200, Loss: 0.137\n",
      "Epoch: 3, Batch: 300, Loss: 0.134\n",
      "Epoch: 3, Batch: 400, Loss: 0.133\n",
      "Epoch: 3, Batch: 500, Loss: 0.146\n",
      "Epoch: 3, Batch: 600, Loss: 0.142\n",
      "Epoch: 3, Batch: 700, Loss: 0.127\n",
      "Epoch: 3, Batch: 800, Loss: 0.120\n",
      "Epoch: 3, Batch: 900, Loss: 0.117\n",
      "Epoch: 4, Batch: 100, Loss: 0.109\n",
      "Epoch: 4, Batch: 200, Loss: 0.104\n",
      "Epoch: 4, Batch: 300, Loss: 0.107\n",
      "Epoch: 4, Batch: 400, Loss: 0.103\n",
      "Epoch: 4, Batch: 500, Loss: 0.104\n",
      "Epoch: 4, Batch: 600, Loss: 0.106\n",
      "Epoch: 4, Batch: 700, Loss: 0.098\n",
      "Epoch: 4, Batch: 800, Loss: 0.100\n",
      "Epoch: 4, Batch: 900, Loss: 0.110\n",
      "Epoch: 5, Batch: 100, Loss: 0.091\n",
      "Epoch: 5, Batch: 200, Loss: 0.092\n",
      "Epoch: 5, Batch: 300, Loss: 0.082\n",
      "Epoch: 5, Batch: 400, Loss: 0.080\n",
      "Epoch: 5, Batch: 500, Loss: 0.098\n",
      "Epoch: 5, Batch: 600, Loss: 0.096\n",
      "Epoch: 5, Batch: 700, Loss: 0.087\n",
      "Epoch: 5, Batch: 800, Loss: 0.077\n",
      "Epoch: 5, Batch: 900, Loss: 0.081\n",
      "Epoch: 6, Batch: 100, Loss: 0.073\n",
      "Epoch: 6, Batch: 200, Loss: 0.069\n",
      "Epoch: 6, Batch: 300, Loss: 0.080\n",
      "Epoch: 6, Batch: 400, Loss: 0.075\n",
      "Epoch: 6, Batch: 500, Loss: 0.080\n",
      "Epoch: 6, Batch: 600, Loss: 0.076\n",
      "Epoch: 6, Batch: 700, Loss: 0.075\n",
      "Epoch: 6, Batch: 800, Loss: 0.079\n",
      "Epoch: 6, Batch: 900, Loss: 0.073\n",
      "Epoch: 7, Batch: 100, Loss: 0.059\n",
      "Epoch: 7, Batch: 200, Loss: 0.065\n",
      "Epoch: 7, Batch: 300, Loss: 0.067\n",
      "Epoch: 7, Batch: 400, Loss: 0.077\n",
      "Epoch: 7, Batch: 500, Loss: 0.069\n",
      "Epoch: 7, Batch: 600, Loss: 0.060\n",
      "Epoch: 7, Batch: 700, Loss: 0.059\n",
      "Epoch: 7, Batch: 800, Loss: 0.071\n",
      "Epoch: 7, Batch: 900, Loss: 0.073\n",
      "Epoch: 8, Batch: 100, Loss: 0.053\n",
      "Epoch: 8, Batch: 200, Loss: 0.059\n",
      "Epoch: 8, Batch: 300, Loss: 0.060\n",
      "Epoch: 8, Batch: 400, Loss: 0.059\n",
      "Epoch: 8, Batch: 500, Loss: 0.054\n",
      "Epoch: 8, Batch: 600, Loss: 0.057\n",
      "Epoch: 8, Batch: 700, Loss: 0.058\n",
      "Epoch: 8, Batch: 800, Loss: 0.068\n",
      "Epoch: 8, Batch: 900, Loss: 0.062\n",
      "Epoch: 9, Batch: 100, Loss: 0.045\n",
      "Epoch: 9, Batch: 200, Loss: 0.047\n",
      "Epoch: 9, Batch: 300, Loss: 0.051\n",
      "Epoch: 9, Batch: 400, Loss: 0.052\n",
      "Epoch: 9, Batch: 500, Loss: 0.054\n",
      "Epoch: 9, Batch: 600, Loss: 0.057\n",
      "Epoch: 9, Batch: 700, Loss: 0.058\n",
      "Epoch: 9, Batch: 800, Loss: 0.055\n",
      "Epoch: 9, Batch: 900, Loss: 0.066\n",
      "Epoch: 10, Batch: 100, Loss: 0.042\n",
      "Epoch: 10, Batch: 200, Loss: 0.040\n",
      "Epoch: 10, Batch: 300, Loss: 0.052\n",
      "Epoch: 10, Batch: 400, Loss: 0.051\n",
      "Epoch: 10, Batch: 500, Loss: 0.048\n",
      "Epoch: 10, Batch: 600, Loss: 0.043\n",
      "Epoch: 10, Batch: 700, Loss: 0.056\n",
      "Epoch: 10, Batch: 800, Loss: 0.049\n",
      "Epoch: 10, Batch: 900, Loss: 0.051\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print(\n",
    "                f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Network on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, move the model back to the cpu to process the test data\n",
    "if device != 'cpu':\n",
    "    model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.52%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(\n",
    "    f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-ML-Bootcamp-24-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
